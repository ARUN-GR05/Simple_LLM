# Simple_LLM ğŸš€

A simple transformer-based language model with a modern **FastAPI backend** and **Next.js frontend**, ready for deployment on Vercel.

## ğŸ“Œ Overview

This project demonstrates:
- **Transformer Architecture**: Self-attention, embeddings, and tokenization
- **Backend API**: FastAPI with text generation endpoints
- **Frontend UI**: Modern React interface with Tailwind CSS
- **Production Ready**: Containerized and deployable to Vercel

## ğŸ“‚ Project Structure

```
Simple_LLM/
â”œâ”€â”€ backend/                 # Python FastAPI server
â”‚   â”œâ”€â”€ app.py              # Main API (endpoints, model init)
â”‚   â”œâ”€â”€ model.py            # Transformer model & tokenizer
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile          # Docker configuration
â”‚   â”œâ”€â”€ .env.example        # Environment template
â”‚   â””â”€â”€ .gitignore
â”œâ”€â”€ frontend/               # Next.js React app
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx       # Main UI (chat interface)
â”‚   â”‚   â”œâ”€â”€ layout.tsx     # App layout
â”‚   â”‚   â””â”€â”€ globals.css    # Tailwind styles
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ .env.local.example # Frontend environment
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ .gitignore
â”œâ”€â”€ simple_LLM.ipynb        # Original Jupyter notebook
â”œâ”€â”€ DEPLOYMENT.md           # Deployment guide
â”œâ”€â”€ vercel.json             # Vercel config
â”œâ”€â”€ setup.bat               # Windows setup script
â”œâ”€â”€ setup.sh                # Linux/Mac setup script
â””â”€â”€ README.md
```

## ğŸš€ Quick Start (Local Development)

### Prerequisites
- **Python 3.11+** (for backend)
- **Node.js 18+** (for frontend)
- **npm** or **yarn**

### 1ï¸âƒ£ Clone & Navigate
```bash
git clone https://github.com/ARUN-GR05/Simple_LLM.git
cd Simple_LLM
```

### 2ï¸âƒ£ Setup Frontend
```bash
cd frontend
npm install
# Create .env.local
echo NEXT_PUBLIC_API_URL=http://localhost:8000 > .env.local
```

### 3ï¸âƒ£ Setup Backend
```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate it
# On Windows: venv\Scripts\activate
# On macOS/Linux: source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run Everything

**Terminal 1 - Backend:**
```bash
cd backend
python app.py
# Runs on http://localhost:8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
# Runs on http://localhost:3000
```

Open http://localhost:3000 in your browser! ğŸ‰

## ğŸŒ Deploy to Vercel + Cloud Backend

See **[DEPLOYMENT.md](DEPLOYMENT.md)** for step-by-step instructions.

**Quick Summary:**
1. Deploy backend to **Render** or **Railway** (free)
2. Deploy frontend to **Vercel** (free)
3. Connect them via environment variables

## ğŸ“Š API Endpoints

### `POST /generate`
Generate text based on a prompt.

**Request:**
```json
{
  "prompt": "The cat sat on",
  "max_length": 20,
  "temperature": 0.7
}
```

**Response:**
```json
{
  "prompt": "The cat sat on",
  "generated_text": "the mat and slept.",
  "full_text": "The cat sat on the mat and slept."
}
```

### `GET /health`
Check API status.

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Next.js 14, React 18, TypeScript, Tailwind CSS |
| **Backend** | FastAPI, Uvicorn |
| **ML** | PyTorch, NumPy |
| **Deployment** | Docker, Vercel, Render/Railway |

## ğŸ“š What You'll Learn

- âœ… Transformer architecture (attention, embeddings)
- âœ… Building REST APIs with FastAPI
- âœ… Modern React with Next.js
- âœ… Full-stack deployment
- âœ… Environment variables & secrets
- âœ… CORS & API integration

## ğŸ”§ Configuration

### Backend `.env`
```bash
FASTAPI_ENV=development
API_PORT=8000
API_HOST=0.0.0.0
```

### Frontend `.env.local`
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| **CORS Error** | Already configured in backend (`CORSMiddleware`) |
| **Module not found** | Run `npm install` (frontend) or `pip install -r requirements.txt` (backend) |
| **Port already in use** | Kill process on port 3000/8000 or change ports |
| **Model fails to load** | Ensure `torch` is installed correctly |

## ğŸš€ Performance Tips

- **Temperature**: Lower (0.1) = deterministic, Higher (2.0) = creative
- **Max tokens**: 20-50 recommended for reasonable speed
- **CPU inference**: Suitable for hobby/demo projects
- **Production**: Consider GPU runtime or model quantization

## ğŸ“– Further Reading

- [PyTorch Docs](https://pytorch.org/docs/)
- [FastAPI Tutorial](https://fastapi.tiangolo.com/tutorial/)
- [Next.js Guide](https://nextjs.org/docs)
- [Vercel Deployment](https://vercel.com/docs)

## ğŸ¤ Contributing

Contributions welcome! Feel free to:
- Add model improvements
- Enhance the UI
- Add more features
- Submit issues & PRs

## ğŸ“ License

MIT License - feel free to use this for learning and projects!

## ğŸ‘¤ Author

**Arun GR**

---

â­ **Found this helpful?** Please star the repository to support the project!

Made with â¤ï¸ for the LLM community
